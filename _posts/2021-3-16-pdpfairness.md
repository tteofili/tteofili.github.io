# Model fairness with partial dependence plots
> A quick guide on how to leverage partial dependence plots to visualize whether an ML model is fair with respect to different groups of people.

As machine learning models, and decision services in general, are used more and more as aiding tools in making decisions that impact human lives, a common 
concern that is often raised relates to **model fairness**.
A "good" _model_ is expected to treat different groups of people the same way; this means that the prediction generated by a model on a given input 
(e.g. grant a loan to a person) would rather not be influenced by sensitive features like _race_, _gender_, _religion_, etc.

On the other hand several studies have witnessed that this is often not the case.
A very well known example of such an unfair model is the one used by COMPAS, an system often used in the U.S. to determine how likely 
a given person is to be a repetead offender. A study on the COMPAS system revelead a highly discriminative behavior, in fact black people were
wrongly reported to be much more likely to commit a crime again with respect to defendants who were white.


In this post we use _Partial Dependence Plots_ to visualize potential fairness concerns in a machine learning model.
A partial dependence plot (or PDP) shows the marginal impact of one (or more) features on the predicted outcome of the model at hand.
PDPs can show whether the relationship between the target and a given feature is linear, monotonic or more complex. 

We leverage some of the nice work from Rui Vieira to analyze [Counterfactual Fairness](https://ruivieira.dev/counterfactual-fairness.html).

We use the "law school" dataset which contains information on 21,790 law students.
For each student it contains the following data: exam scores (LSAT), grade-point average (GPA) collected prior to law school, their first year average 
grade (FYA). 
We train a model to predict if an applicant will have a high first year average grade (FYA). 
At the same time we want to check whether our trained model is fair with respect to students' _race_ and _gender_.

As in Rui's post, we train a _scikit-learn_ linear regression model to predict FYA.
In this example we use all the available features on purpose, as we expect the model to show an unfair behaviour.


```python
import pandas as pd

df = pd.read_csv("law_data.csv", index_col=0)
df.head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>race</th>
      <th>sex</th>
      <th>LSAT</th>
      <th>UGPA</th>
      <th>region_first</th>
      <th>ZFYA</th>
      <th>sander_index</th>
      <th>first_pf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>White</td>
      <td>1</td>
      <td>39.0</td>
      <td>3.1</td>
      <td>GL</td>
      <td>-0.98</td>
      <td>0.782738</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>White</td>
      <td>1</td>
      <td>36.0</td>
      <td>3.0</td>
      <td>GL</td>
      <td>0.09</td>
      <td>0.735714</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>White</td>
      <td>2</td>
      <td>30.0</td>
      <td>3.1</td>
      <td>MS</td>
      <td>-0.35</td>
      <td>0.670238</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Hispanic</td>
      <td>2</td>
      <td>39.0</td>
      <td>2.2</td>
      <td>NE</td>
      <td>0.58</td>
      <td>0.697024</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>White</td>
      <td>1</td>
      <td>37.0</td>
      <td>3.4</td>
      <td>GL</td>
      <td>-1.26</td>
      <td>0.786310</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df = pd.get_dummies(df, columns=["race"], prefix="", prefix_sep="")
df.iloc[:, : 7].head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>LSAT</th>
      <th>UGPA</th>
      <th>region_first</th>
      <th>ZFYA</th>
      <th>sander_index</th>
      <th>first_pf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>39.0</td>
      <td>3.1</td>
      <td>GL</td>
      <td>-0.98</td>
      <td>0.782738</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>36.0</td>
      <td>3.0</td>
      <td>GL</td>
      <td>0.09</td>
      <td>0.735714</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>30.0</td>
      <td>3.1</td>
      <td>MS</td>
      <td>-0.35</td>
      <td>0.670238</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>39.0</td>
      <td>2.2</td>
      <td>NE</td>
      <td>0.58</td>
      <td>0.697024</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>37.0</td>
      <td>3.4</td>
      <td>GL</td>
      <td>-1.26</td>
      <td>0.786310</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.iloc[:, 7 :].head()

```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Amerindian</th>
      <th>Asian</th>
      <th>Black</th>
      <th>Hispanic</th>
      <th>Mexican</th>
      <th>Other</th>
      <th>Puertorican</th>
      <th>White</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
df["male"] = df["sex"].map(lambda x: 1 if x == 2 else 0)
df["female"] = df["sex"].map(lambda x: 1 if x == 1 else 0)
df = df.drop(axis=1, columns=["sex"])
```


```python
df.iloc[:, 0:7].head()

```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LSAT</th>
      <th>UGPA</th>
      <th>region_first</th>
      <th>ZFYA</th>
      <th>sander_index</th>
      <th>first_pf</th>
      <th>Amerindian</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39.0</td>
      <td>3.1</td>
      <td>GL</td>
      <td>-0.98</td>
      <td>0.782738</td>
      <td>1.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36.0</td>
      <td>3.0</td>
      <td>GL</td>
      <td>0.09</td>
      <td>0.735714</td>
      <td>1.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>30.0</td>
      <td>3.1</td>
      <td>MS</td>
      <td>-0.35</td>
      <td>0.670238</td>
      <td>1.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>39.0</td>
      <td>2.2</td>
      <td>NE</td>
      <td>0.58</td>
      <td>0.697024</td>
      <td>1.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>37.0</td>
      <td>3.4</td>
      <td>GL</td>
      <td>-1.26</td>
      <td>0.786310</td>
      <td>1.0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.iloc[:, 7:].head()

```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Asian</th>
      <th>Black</th>
      <th>Hispanic</th>
      <th>Mexican</th>
      <th>Other</th>
      <th>Puertorican</th>
      <th>White</th>
      <th>male</th>
      <th>female</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
df["LSAT"] = df["LSAT"].astype(int)
df.iloc[:, :6].head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LSAT</th>
      <th>UGPA</th>
      <th>region_first</th>
      <th>ZFYA</th>
      <th>sander_index</th>
      <th>first_pf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>3.1</td>
      <td>GL</td>
      <td>-0.98</td>
      <td>0.782738</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36</td>
      <td>3.0</td>
      <td>GL</td>
      <td>0.09</td>
      <td>0.735714</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>30</td>
      <td>3.1</td>
      <td>MS</td>
      <td>-0.35</td>
      <td>0.670238</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>39</td>
      <td>2.2</td>
      <td>NE</td>
      <td>0.58</td>
      <td>0.697024</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>37</td>
      <td>3.4</td>
      <td>GL</td>
      <td>-1.26</td>
      <td>0.786310</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.iloc[:, 6:].head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Amerindian</th>
      <th>Asian</th>
      <th>Black</th>
      <th>Hispanic</th>
      <th>Mexican</th>
      <th>Other</th>
      <th>Puertorican</th>
      <th>White</th>
      <th>male</th>
      <th>female</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
A = [
    "Amerindian",
    "Asian",
    "Black",
    "Hispanic",
    "Mexican",
    "Other",
    "Puertorican",
    "White",
    "male",
    "female",
]
```


```python
df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>LSAT</th>
      <th>UGPA</th>
      <th>region_first</th>
      <th>ZFYA</th>
      <th>sander_index</th>
      <th>first_pf</th>
      <th>Amerindian</th>
      <th>Asian</th>
      <th>Black</th>
      <th>Hispanic</th>
      <th>Mexican</th>
      <th>Other</th>
      <th>Puertorican</th>
      <th>White</th>
      <th>male</th>
      <th>female</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>3.1</td>
      <td>GL</td>
      <td>-0.98</td>
      <td>0.782738</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>36</td>
      <td>3.0</td>
      <td>GL</td>
      <td>0.09</td>
      <td>0.735714</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>30</td>
      <td>3.1</td>
      <td>MS</td>
      <td>-0.35</td>
      <td>0.670238</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>39</td>
      <td>2.2</td>
      <td>NE</td>
      <td>0.58</td>
      <td>0.697024</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>37</td>
      <td>3.4</td>
      <td>GL</td>
      <td>-1.26</td>
      <td>0.786310</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



```python
from sklearn.model_selection import train_test_split

df_train, df_test = train_test_split(df, random_state=23, test_size=0.2);
```


```python
from sklearn.linear_model import LinearRegression

linreg_unfair = LinearRegression()
```


```python
import numpy as np

X = np.hstack(
    (
        df_train[A],
        np.array(df_train["UGPA"]).reshape(-1, 1),
        np.array(df_train["LSAT"]).reshape(-1, 1),
    )
)
print(X)
```

    [[ 0.   0.   0.  ...  1.   3.1 39. ]
     [ 0.   0.   0.  ...  1.   3.5 36. ]
     [ 0.   0.   0.  ...  1.   3.9 46. ]
     ...
     [ 0.   0.   0.  ...  1.   2.9 33. ]
     [ 0.   0.   0.  ...  0.   2.9 31. ]
     [ 0.   0.   0.  ...  0.   3.6 39. ]]



```python
y = df_train["ZFYA"]
y[:10]
```




    10454    0.56
    14108    0.60
    20624   -0.14
    8316     0.20
    14250    0.02
    18909   -1.47
    8949     1.36
    1658     0.39
    23340    0.10
    26884    0.48
    Name: ZFYA, dtype: float64




```python
linreg_unfair = linreg_unfair.fit(X, y)
```


```python
X_test = np.hstack(
    (
        df_test[A],
        np.array(df_test["UGPA"]).reshape(-1, 1),
        np.array(df_test["LSAT"]).reshape(-1, 1),
    )
)
X_test
```




    array([[ 0. ,  0. ,  0. , ...,  0. ,  3.4, 32. ],
           [ 0. ,  0. ,  0. , ...,  1. ,  3.5, 41. ],
           [ 0. ,  0. ,  0. , ...,  1. ,  3.9, 42. ],
           ...,
           [ 0. ,  0. ,  0. , ...,  0. ,  2.3, 28. ],
           [ 0. ,  0. ,  0. , ...,  0. ,  3.3, 36. ],
           [ 0. ,  0. ,  0. , ...,  0. ,  2.9, 37. ]])




```python
predictions_unfair = linreg_unfair.predict(X_test)
predictions_unfair
```




    array([ 0.08676147,  0.34942627,  0.4609375 , ..., -0.25949097,
            0.19308472,  0.14471436])




```python
from sklearn.metrics import mean_squared_error

RMSE_unfair = np.sqrt(mean_squared_error(df_test["ZFYA"], predictions_unfair))
print(RMSE_unfair)
```

    0.8666709890234552


We have now finished training our linear regression model.

At this point we persist the existing _sklearn_ module as a _PMML_ model onto disk.
This will allow us to use the **TrustyAI** explainability library to generate Partial Dependence Plots for all the involved features.

```python
from sklearn2pmml.pipeline import PMMLPipeline

pipeline = PMMLPipeline([
    ("regressor", linreg_unfair)
])
pipeline.fit(X, y)

from sklearn2pmml import sklearn2pmml

sklearn2pmml(pipeline, "sample.pmml", with_repr = True)
```

Once the model has been saved to disk.
We further create a pandas dataframe for the training data and persist _inputs_ and _target_ separately to disk as CSVs.

```python
altered_train = pd.DataFrame(X)
y_df = pd.DataFrame(y)

altered_train.columns = A + ["UGPA", "LSAT"]

altered_train.to_csv('inputs.csv')
y_df.to_csv('target.csv')
```

At this point we can use TrustyAI library to generate PDPs for the PMML model.
We load the PMML model using Kogito `kie-pmml-api` module and wrap it as a generic `PredictionProvider` using TrustyAI `explainability-core` library (from `kogito-apps`).

```java
PMMLRuntime pmmlRuntime = getPMMLRuntime(new File("sample.pmml"));

PredictionProvider model = inputs -> CompletableFuture.supplyAsync(() -> {
    List<PredictionOutput> outputs = new ArrayList<>();
    for (PredictionInput input : inputs) {
        Map<String, Object> map = new HashMap<>();
        int i = 1;
        for (Feature f : input.getFeatures()) {
            map.put("x" + i, f.getValue().asNumber());
            i++;
        }
        final PMMLRequestData pmmlRequestData = getPMMLRequestData("sampleRegressionModel0", map);
        final PMMLContext pmmlContext = new PMMLContextImpl(pmmlRequestData);
        PMML4Result pmml4Result = pmmlRuntime.evaluate("sampleRegressionModel0", pmmlContext);
        Map<String, Object> resultVariables = pmml4Result.getResultVariables();
        String zfya = "" + resultVariables.get("ZFYA");
        PredictionOutput predictionOutput = new PredictionOutput(List.of(
                new Output("ZFYA", Type.NUMBER, new Value(zfya), 1d)));
        outputs.add(predictionOutput);
    }
    return outputs;
});
```

Let's load the training data to obtain the data distribution we can use to generate partial dependence plots.

```java
List<Type> schema = new ArrayList<>(); // define the type of each feature in the training data
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
schema.add(Type.NUMBER);
DataDistribution dataDistribution = DataUtils.readCSV(Paths.get("inputs.csv"), schema, true);
```

We can now instantiate a `PartialDependenceExplainer` (from `explainability-core`), that we'll use to generate PDPs.

```java
PartialDependencePlotExplainer explainer = new PartialDependencePlotExplainer();
PredictionProviderMetadata metadata = new PredictionProviderMetadata() {
    @Override
    public DataDistribution getDataDistribution() {
        return dataDistribution;
    }
...
    @Override
    public PredictionOutput getOutputShape() {
        return new PredictionOutput(List.of(new Output("ZFYA", Type.NUMBER)));
    }
};
```

We can generate partial dependence plots for all the input features.

```java
List<PartialDependenceGraph> partialDependenceGraphs = explainer.explainFromMetadata(model, metadata);
for (PartialDependenceGraph pdg : partialDependenceGraphs) {
    DataUtils.toCSV(pdg, Paths.get(pdg.getFeature().getName() + "_" + pdg.getOutput().getName() + ".csv"));
}
```

We know that UGPA (grade point average) and LSAT (entrance exam scores) features are likely to have a monotonicly increasingly impact on the expected average grade for a student's first year (ZFYA).
Let's analyse the resulting PDP for such features:

![png](/images/pdpfairness_files/ugpa.png)
![png](/images/pdpfairness_files/lsat.png)

The impact on the average grade is, as expected, growing both when LSAT and UGPA grow, in a linear fashion.

Let's now look at the more sensitive features that indicate *race*, unfortunately the model seems biased towards predicting higher grades for *white* people with respect to *black* people.

![png](/images/pdpfairness_files/white.png)
![png](/images/pdpfairness_files/black.png)

If we look closer at other ethnicities we see the model seems unfair towards all of them. 
In summary it seems this model is positively biased towards white people and negatively biased towards anyone else. 

![png](/images/pdpfairness_files/hispanic.png)
![png](/images/pdpfairness_files/asian.png)
![png](/images/pdpfairness_files/mexican.png)
![png](/images/pdpfairness_files/puertorican.png)

Partial depdendence plots provide a very intuitive look into how the model treats a certain feature *in isolation* with respect to any other feature; this makes them particularly useful to look into potential fairness concerns.

## References

[TrustyAI Initiative](https://kogito.kie.org/trustyai/)

[Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html)

[Greedy function approximation: A gradient boosting machine](https://www.researchgate.net/publication/2424824_Greedy_Function_Approximation_A_Gradient_Boosting_Machine)

[The Fairness of Credit Scoring Models](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3785882)
