# Notes from today
> Apr 27th 2023

## TrustyAI Explainability Research
we've been discussing a few new algorithms to be included within TrustyAI, either by means of (re)implementing them or by including other third party libraries (e.g. by means of an integration layer, sidecar container, etc.).
In particular we have focused on explaining time series related models by means of: dedicated [ICE plot explainers](https://christophm.github.io/interpretable-ml-book/ice.html), linear autoregressive explainers, SHAP.
shap explainer. Other topics covered include algorithsm for data and model drift detection.
Another thing discussed is [uncertainty quantification](https://arxiv.org/abs/2201.07766), see [uq360](https://github.com/IBM/UQ360/tree/main/uq360/algorithms/blackbox_metamodel) for example.

## ChatGPT for Entity Resolution
I've taken a few minutes to try and see how much reliable ChatGPT is in the context of Entity Resolution (ER).
Is it able to correctly predict cases that fool other (good performing) models? 
Is it able to explain its predictions ? 
Is it able to predict/explain what other models do ?
I've summarized the transcript in this [document](https://docs.google.com/document/d/1BJAagwg490plseLhKyVoduc3mVugif3ysDxuc2LC164/edit?usp=sharing).
It turns out ChatGPT doesn't make the same mistakes some other models do (DeepER, DeepMatcher, Ditto), but it cannot explain such other models' failures, it could just suggest interesting possibilities but didn't have ways of actually finding anything out about the models' weird behaviors.
All in all, ChatGPT is good at performing ER, has some global sense of similarities and possible causes of misunderstandings, but it stops there. I hould try to confuse ChatGPT with harder samples.

## Enabling XAI for modelmesh
I've worked on a small PR to include the prediction endpoint as part of the _modelmesh_ `Payload`:

https://github.com/kserve/modelmesh/pull/91

However, it sounds like we could get away with just needing the service name, as we can then make the TrustyAI service to know where _modelmesh_ is and delegate to it for calling the model, by leveraging [KServeV2GRPCPredictionProvider](https://github.com/trustyai-explainability/trustyai-explainability/blob/main/explainability-connectors/src/main/java/org/kie/trustyai/connectors/kserve/v2/KServeV2GRPCPredictionProvider.java).

## TrustyAI+modelmesh documentation
I'm putting in place some documentation on how to plug modelmesh and the TrustyAI service, leverging nice docs from [Rui](https://github.com/ruivieira/trustyai-service-examples/blob/main/scripts/basic_k8s_deployment.sh) and [JooHo](https://github.com/Jooho/jhouse_openshift/blob/main/Kserve/docs/Modelmesh/ModelMesh-upstream-on-kind.md).
