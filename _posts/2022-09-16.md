# Some thoughts about VLDB 2022
> Interesting stuff from [VLDB 2022](https://vldb.org/2022) in Sydney

## The unreasonable effectiveness (?) of ML for anything-database related

Transforming SQL queries into [tensor programs](https://www.vldb.org/pvldb/vol15/p2811-he.pdf)).
Database systems which run (fully or partially) over neural networks, e.g. for performing [spatial range queries](https://www.vldb.org/pvldb/vol15/p1066-zeighami.pdf) (with differential privacy guarantees), or ...

_Learned_ indexes seem to be very popular and are reported to be replacing common physical indexes, e.g. [recursive model indexes](https://www.vldb.org/pvldb/vol15/p1079-maltry.pdf), 

Machine learning is being used in nearly every possible way for query processing: like for example in [parametric query optimization](https://www.vldb.org/pvldb/vol15/p401-vaidya.pdf) but also to perform query cost prediction using [zero shot learning](https://www.vldb.org/pvldb/vol15/p2361-hilprecht.pdf) or estimating the number of distinct values [using supervised learning](https://www.vldb.org/pvldb/vol15/p272-wu.pdf). 
To some extent, some typical such tasks are becoming natural language processing tasks, as an example there's an interesting work to efficiently perform cardinality estimation by [pre-training summarization models of structured datasets](https://www.vldb.org/pvldb/vol15/p414-lu.pdf); other alternatives for performing cardinality estimation still rely on [machine learning techniques](https://vldb.org/pvldb/vol15/p85-li.pdf).

More generally database workload characterization is also being addressed by means of [deep learning techniques](https://www.vldb.org/pvldb/vol15/p923-paul.pdf) or [reinforcement learning](https://vldb.org/pvldb/vol14/p3402-wang.pdf).

Other aspects involve designing storage optimizations on databases systems like [model serving of deep learning models](https://www.vldb.org/pvldb/vol15/p2230-zou.pdf) or [selecting the best storage settings via machine learning](https://www.vldb.org/pvldb/vol15/p3126-abebe.pdf).



On one hand this is all very nice and interesting (especially if you like to work with machine learning), however it also seems that some works presented at VLDB this year might have been submitted (also) to some more generic ML venues like ICML, NeurIPS, AAAI, etc. 
For example the interesting work [ByteGNN: Efficient Graph Neural Network Training at Large Scale](https://www.vldb.org/pvldb/vol15/p1228-zheng.pdf) seems a quite generic (and good) one that seems a bit too much "just-ML" oriented for a database/data management kind of conference.


## Explainability

[Efficient and Effective Data Imputation with Influence Functions](https://www.vldb.org/pvldb/vol15/p624-miao.pdf)

[Analyzing How BERT Performs Entity Matching](https://www.vldb.org/pvldb/vol15/p1726-paganelli.pdf), this work analyses how BERT based models for the _entity resolution_ task performs its predictions. An interesting insight is that _"the pair-wise semantic similarity of tokens is not a key knowledge exploited by BERT-based EM models"_; this finding, while somewhat expected if you have ever worked with one of those models, might sound surprising since this is counterintuitive with respect to how humans typically think to the entity matching task (semantic similarity between aligned pairs of text sounds important to decide if two records refer to the same entity).

The work title [DeepEverest: Accelerating Declarative Top-K Qeries for Deep Neural Network Interpretation](https://www.vldb.org/pvldb/vol15/p98-he.pdf) describes a system for the efficient execution of "interpretation by example" queries over the activation values of a deep neural network. This basically speeds up white box explanation techniques for deep neural networks that "look" at neurons' activations.

Despite not strictly dealing with ExplainableAI, the paper [On Shapley Value in Data Assemblage Under Independent Utility](https://www.vldb.org/pvldb/vol15/p2761-luo.pdf) provides an interesting take on evaluating the quality of data by means of Shapley fairness under the independent utility assumption.

## Best paper (awarded)

[HET: Scaling out Huge Embedding Model Training via Cache-enabled Distributed Framework](https://www.vldb.org/pvldb/vol15/p312-miao.pdf) (best scalabale data science paper)

[Sancus: Staleness-Aware Communication-Avoiding Full-Graph Decentralized Training in Large-Scale Graph Neural Networks](https://vldb.org/pvldb/vol15/p1937-peng.pdf) (best regular research paper)

[Threshold Queries in Theory and in the Wild](https://www.vldb.org/pvldb/vol15/p1105-staworko.pdf) (best regular research paper runner ups)

[Sortledton: a universal, transactional graph data structure](https://www.vldb.org/pvldb/vol15/p1173-fuchs.pdf) (best regular research paper runner ups)

[Accurate Summary-based Cardinality Estimation Through the Lens of Cardinality Estimation Graphs](https://www.vldb.org/pvldb/vol15/p1533-chen.pdf) (best experiment, analysis and benchmark paper)

[Hardware Acceleration of Compression and Encryption in SAP HANA](https://www.vldb.org/pvldb/vol15/p3277-chiosa.pdf) (best industry paper)

## Interesting papers (imho)

[Deep Transfer Learning for Multi-source Entity Linkage via Domain Adaptation](https://www.vldb.org/pvldb/vol15/p465-jin.pdf)

[Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins](https://www.vldb.org/pvldb/vol15/p699-suri.pdf)

The paper [Entity Resolution On-Demand](https://www.vldb.org/pvldb/vol15/p1506-simonini.pdf) introduces _BrewER_, a framework to evaluate SQL queries on dirty data while progressively returning results as if they were issued on cleaned data. The interesting aspect of _BrewER_ is that it tries to focus on the cleaning effort on one entity at a time following an _ORDER BY_ predicate, saving a significant amount of resources.

[Fast Neural Ranking on Bipartite Graph Indices](https://www.vldb.org/pvldb/vol15/p794-tan.pdf)

[LANNS: A Web-Scale Approximate Nearest Neighbor Lookup System](https://www.vldb.org/pvldb/vol15/p850-doshi.pdf)

## Sydney

Sydney is a modern beautiful city, at least for what concerns downtown and surroundings (Haymarket, Darling Harbour, Pott's point, etc.).
